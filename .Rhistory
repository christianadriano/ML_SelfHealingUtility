#Load utility functions
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_SelfHealingUtility//loadData.R");
library(xgboost)
library(r2pmml) #https://github.com/jpmml/r2pmml
library(devtools)
library(xgboost)
library(r2pmml) #https://github.com/jpmml/r2pmml
#Load utility functions
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
# Generate the dataset names that will be trained -------------------------
generateDataSetNames <- function(modelName,datasetSize,s_idx){
if(s_idx==0 & length(datasetSize)>0){#Generate for all sizes
datasetName <- paste0(modelName,datasetSize[1]);
for(i in c(2:length(datasetSize))){
datasetName <- cbind(datasetName,paste0(modelName,datasetSize[i]));
}
}
else{
datasetName <- paste0(modelName,datasetSize[s_idx]);
}
return(datasetName);
}
# Save results to file ----------------------------------------------------
resultsToFile <- function(mcResults,modelName,extension){
fileName <- paste0("mcResultsf_",modelName,extension);
write.table(mcResults,fileName,sep=",",col.names = TRUE);
print(paste0("file written:",fileName));
mcResults
}
# Prepare features --------------------------------------------------------
prepareFeatures <- function(dataf,selectionType){
#Do feature selection (or not)
if(selectionType=="ALL")
featuresdf<- select_ALL(dataf)
else
if(selectionType=="Linear")
featuresdf<- select_Linear(dataf)
else
if(selectionType=="Discontinuous")
featuresdf<- select_Discontinuous(dataf)
else
if(selectionType=="Saturating")
featuresdf<- select_Saturation(dataf)
#Remove zero utilities
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
# Scramble data
featuresdf <- scrambleData(datadf=featuresdf);
return (featuresdf);
}
# Train function  ---------------------------------------------------------
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 2500,
early_stopping_rounds = 500, metrics='rmse',verbose = FALSE)
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
return(list(xgb.model,xgboost.cv));
}
# Validation -------------------------------------------------------------
validatePredictions <- function(modelList, mcResultsf,validationData){
xgb.model <- modelList[[1]];
xgboost.cv <- modelList[[2]];
best_iteration <- xgboost.cv$best_iteration;
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
best_iteration <- xgboost.cv$best_iteration;
mcResultsf$DataSet[i]<-datasetName[i];
mcResultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
mcResultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
mcResultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
mcResultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
mcResultsf$RMSE[i] <- rmse(error);
mcResultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
mcResultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
return(mcResultsf);
}
#Data structure to keep results
mcResultsf <- data.frame(matrix(data=NA,nrow=3,ncol=8));
colnames(mcResultsf) <- c("DataSet","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
for(i in c(1:length(datasetName))){
#i <- 2;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Linear");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
#Compute results
mcResultsf <- validatePredictions(outcomeList,mcResultsf,validationData);
}
resultsToFile(mcResultsf,modelName,"_70-30_FeatureSelection.csv"); #save to a .csv file
modelName <- modelList[2];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
for(i in c(1:length(datasetName))){
#i <- 2;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Linear");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
#Compute results
mcResultsf <- validatePredictions(outcomeList,mcResultsf,validationData);
}
resultsToFile(mcResultsf,modelName,"_70-30_FeatureSelection.csv"); #save to a .csv file
modelName <- modelList[2];
datasetName <- generateDataSetNames(modelName,datasetSize,0);
for(i in c(1:length(datasetName))){
#i <- 2;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Discontinuous");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
#Compute results
mcResultsf <- validatePredictions(outcomeList,mcResultsf,validationData);
}
resultsToFile(mcResultsf,modelName,"_70-30_FeatureSelection.csv"); #save to a .csv file
modelName <- modelList[3];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
for(i in c(1:length(datasetName))){
#i <- 2;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
#Compute results
mcResultsf <- validatePredictions(outcomeList,mcResultsf,validationData);
}
resultsToFile(mcResultsf,modelName,"_70-30_FeatureSelection.csv"); #save to a .csv file
