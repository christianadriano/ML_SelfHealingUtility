resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
dataf <-loadData(fileName="data//10000//Probabilistic10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
resultsf <- data.frame(matrix(data=NA,nrow=5,ncol=8));
colnames(resultsf) <- c("DataSet","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD");
featuresdf<- select_LinearProbabilistic(dataf)
inputFeatures <- dim(featuresdf)[2] - 1;
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
index=0;
dataf <-loadData(fileName="data//10000//Linear10000.csv"); #3.96% MAPD
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
index=0;
resultsf <- data.frame(matrix(data=NA,nrow=5,ncol=8));
colnames(resultsf) <- c("DataSet","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD");
dataf <-loadData(fileName="data//10000//Linear10000.csv"); #3.96% MAPD
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
# Select feature columns --------------------------------------------------
featuresdf<- select_LinearProbabilistic(dataf)
inputFeatures <- dim(featuresdf)[2] - 1;
#
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_SelfHealingUtility//loadData.R");
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_SelfHealingUtility//loadData.R");
dataf <-loadData(fileName="data//10000//Probabilistic10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
featuresdf<- select_Probabilistic(dataf)
inputFeatures <- dim(featuresdf)[2] - 1;
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_SelfHealingUtility//loadData.R");
index=0;
resultsf <- data.frame(matrix(data=NA,nrow=5,ncol=8));
colnames(resultsf) <- c("DataSet","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD");
dataf <-loadData(fileName="data//10000//Linear10000.csv"); #3.96% MAPD
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
featuresdf<- select_Linear(dataf) #Probabilistic
select_Linear <- function(dataf){
# Select feature columns --------------------------------------------------
featuresdf<- data.frame(dataf$CRITICALITY,dataf$CONNECTIVITY,dataf$RELIABILITY,
dataf$UTILITY_INCREASE);
colnames(featuresdf) <- c("CRITICALITY","CONNECTIVITY","RELIABILITY",
"UTILITY_INCREASE");
return(featuresdf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_SelfHealingUtility//loadData.R");
index=0;
resultsf <- data.frame(matrix(data=NA,nrow=5,ncol=8));
colnames(resultsf) <- c("DataSet","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD");
dataf <-loadData(fileName="data//10000//Linear10000.csv"); #3.96% MAPD
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
# Select feature columns --------------------------------------------------
featuresdf<- select_Linear(dataf) #Probabilistic
inputFeatures <- dim(featuresdf)[2] - 1;
#
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
dataf <-loadData(fileName="data//10000//Probabilistic10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
featuresdf<- select_Probabilistic(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
dataf <- loadData(fileName="data//10000//discontinous10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
# Select feature columns --------------------------------------------------
featuresdf<- select_Discontinous(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
#
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
dataf <- loadData(fileName="data//10000//Saturating10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
# Select feature columns --------------------------------------------------
featuresdf<- select_Saturation(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
#
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
dataf <- loadData(fileName="data//10000//ALL10000.csv");
index=index+1;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
featuresdf<- select_ALL(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$Utility_Increase;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
select_ALL <- function(dataf){
# Select feature columns --------------------------------------------------
featuresdf<- data.frame(dataf$CRITICALITY,dataf$RELIABILITY,dataf$IMPORTANCE,
dataf$PROVIDED_INTERFACE, dataf$REQUIRED_INTERFACE,
dataf$REPLICA,dataf$REQUEST,dataf$ADT,
dataf$PMax,dataf$alpha,
dataf$UTILITY_INCREASE);
colnames(featuresdf) <- c("CRITICALITY","RELIABILITY","IMPORTANCE",
"PROVIDED_INTERFACE", "REQUIRED_INTERFACE",
"REPLICA" ,"REQUEST","ADT",
"PMax","alpha",
"UTILITY_INCREASE");
return(featuresdf);
}
dataf <- loadData(fileName="data//10000//ALL10000.csv");
index=5;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
featuresdf<- select_ALL(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
select_ALL <- function(dataf){
# Select feature columns --------------------------------------------------
featuresdf<- data.frame(dataf$CRITICALITY,dataf$RELIABILITY,
dataf$PROVIDED_INTERFACE, dataf$REQUIRED_INTERFACE,
dataf$REPLICA,dataf$REQUEST,dataf$ADT,
dataf$PMax,dataf$alpha,
dataf$UTILITY_INCREASE);
colnames(featuresdf) <- c("CRITICALITY","RELIABILITY",
"PROVIDED_INTERFACE", "REQUIRED_INTERFACE",
"REPLICA" ,"REQUEST","ADT",
"PMax","alpha",
"UTILITY_INCREASE");
return(featuresdf);
}
dataf <- loadData(fileName="data//10000//ALL10000.csv");
index=5;
datasetName <- c("linear10K","Probilistic10K","Discontinous10K","Saturation10K","ALL10K");
dataf <- renameAuthenticationServices(dataf)
#dataf <- dataf[dataf$AFFECTED_COMPONENT=="Authentication Service",];
# Select feature columns --------------------------------------------------
featuresdf<- select_ALL(dataf) #
inputFeatures <- dim(featuresdf)[2] - 1;
#
proportion <- 0.75
featuresdf <- featuresdf[featuresdf$UTILITY_INCREASE!=0,];
i <- index;
#for(i in c(1:10)){
# Scramble data -----------------------------------------------------------
featuresdf <- scrambleData(dataf=featuresdf);
# Extract training ad validation sets -------------------------------------
#Training = used to create a model
#Validation = used to compute prediction error (Bias)
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * proportion);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
# Build model -------------------------------------------------------------
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)
xgboost.cv = xgb.cv(param=param, data = xgb.train.data, nfold = 10, nrounds = 1500,
early_stopping_rounds = 100, metrics='rmse')
best_iteration <- xgboost.cv$best_iteration;
xgboost.cv$evaluation_log[best_iteration]
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
# Validation -------------------------------------------------------------
y_pred <- predict(xgb.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
resultsf$DataSet[i]<-datasetName[i];
resultsf$Train_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_mean;
resultsf$Train_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$train_rmse_std;
resultsf$Test_RMSE_MEAN[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_mean;
resultsf$Test_RMSE_STD[i]<-xgboost.cv$evaluation_log[best_iteration]$test_rmse_std;
resultsf$RMSE[i] <- rmse(error);
resultsf$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
resultsf$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
#}
resultsf
