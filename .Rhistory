features.df <- scrambleData(datadf=features.df);
return (features.df);
}
# Generate PMML file ------------------------------------------------------
generatePMML <- function(model, features.df, modelName, numberOfTrees){
inputFeatures <- dim(features.df)[2] - 1; #last column is the target variable
# Generate feature map
feature.map = r2pmml::genFMap(features.df[1:inputFeatures])
r2pmml::writeFMap(feature.map, "feature.map")
# Save the model in XGBoost proprietary binary format
xgb.save(model, "xgboost.model")
# Dump the model in text format
#  xgb.dump(model, "xgboost.model.txt", fmap = "feature.map");
pmmlFileName <- paste0(".//pmml///",modelName,"-xgb.pmml");
r2pmml(model, pmmlFileName, fmap = feature.map, response_name = "UTILITY_INCREASE",
missing = NULL, ntreelimit = numberOfTrees, compact = TRUE)
}
# Convert time to Data Frame ----------------------------------------------
convertTimeToDataFrame <- function(time.elapsed){
user.self <-unlist(lapply(time.elapsed, '[[', 1));
sys.self <- unlist(lapply(time.elapsed, '[[', 2));
elapsed.self <-unlist(lapply(time.elapsed, '[[', 3))
time.df <- data.frame(matrix(data=NA,nrow=1,ncol=3));
colnames(time.df) <- c("user.time","sys.time","elapse.time");
time.df$user.time <- user.self;
time.df$sys.time<- sys.self;
time.df$elapsed.time <- elapsed.self;
return (time.df);
}
# Train function  ---------------------------------------------------------
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
return(list(best.model,trained.model, convertTimeToDataFrame(time)));
}
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
#folder <- "//DataPoints_1K-3K-9K//";
# CONTROL CODE   ------------------------------------------------------------
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
time
unlist(lapply(time, '[[', 1))
unlist(lapply(time, '[[', 2))
unlist(lapply(time, '[[', 3))
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
#folder <- "//DataPoints_1K-3K-9K//";
# CONTROL CODE   ------------------------------------------------------------
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
return(list(best.model,trained.model, convertTimeToDataFrame(time)));
}
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
convertTimeToDataFrame(time)
return(list(best.model,trained.model, convertTimeToDataFrame(time)));
}
#Train model
outcomeList <- trainModel(trainingData);
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
#convertTimeToDataFrame(time)
return(list(best.model,trained.model, time));# convertTimeToDataFrame(time)));
}
#Train model
outcomeList <- trainModel(trainingData);
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
convertTimeToDataFrame(time)
return(list(best.model,trained.model, time));# convertTimeToDataFrame(time)));
}
#Train model
outcomeList <- trainModel(trainingData);
unlist(lapply(outcomeList[3], '[[', 1))
user.self <- unlist(lapply(outcomeList[3], '[[', 1))
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
#folder <- "//DataPoints_1K-3K-9K//";
# CONTROL CODE   ------------------------------------------------------------
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
time.df <- data.frame(matrix(data=NA,nrow=1,ncol=3));
colnames(time.df) <- c("user.time","sys.time","elapse.time");
time<-outcomeList[3]
time.df$user.time <- unlist(lapply(time, '[[', 1));
time.df$sys.time <- unlist(lapply(time, '[[', 2));
time.df$elapsed.time <-unlist(lapply(time, '[[', 3));
time.df
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
#convertTimeToDataFrame(time)
return(list(best.model,trained.model, time));# convertTimeToDataFrame(time)));
}
# Validation -------------------------------------------------------------
validatePredictions <- function(modelList, results.df,validationData){
best.model <- modelList[[1]];
trained.model <- modelList[[2]];
best_iteration <- trained.model$best_iteration;
y_pred <- predict(best.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
best_iteration <- trained.model$best_iteration;
results.df$Item[i] = "";
results.df$Utility_Type[i]<-datasetName[i];
results.df$Train_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_mean;
results.df$Train_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_std;
results.df$Test_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_mean;
results.df$Test_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_std;
results.df$RMSE[i] <- rmse(error);
results.df$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
results.df$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
results.df$User_Time[i] <- outcomeList$user.time;
results.df$Sys_Time[i] <- outcomeList$sys.time;
results.df$Elapsed_Time[i] <- outcomeList$elapsed.time;
return(results.df);
}
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
#folder <- "//DataPoints_1K-3K-9K//";
# CONTROL CODE   ------------------------------------------------------------
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
convertTimeToDataframe(outcomeList[3])
convertTimeToDataFrame(outcomeList[3])
time <- outcomeList[3]
time
time.df <- data.frame(matrix(data=NA,nrow=1,ncol=3));
colnames(time.df) <- c("user.time","sys.time","elapse.time");
time.df$user.time <- unlist(lapply(time, '[[', 1));
time.df
time.df$sys.time <- unlist(lapply(time, '[[', 2));
time.df
time.df$elapsed.time <-unlist(lapply(time, '[[', 3));
time.df$elapsed.time <-unlist(lapply(time, '[[', 3));
time.df
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Load utility functions
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
convertTimeToDataFrame(outcomeList[3])
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
#convertTimeToDataFrame(time)
return(list(best.model,trained.model, convertTimeToDataFrame(time)));
}
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
#Compute results
results.df <- validatePredictions(outcomeList,results.df,validationData);
validatePredictions <- function(modelList, results.df,validationData){
best.model <- modelList[[1]];
trained.model <- modelList[[2]];
time.df <- modelList[3]
best_iteration <- trained.model$best_iteration;
y_pred <- predict(best.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
best_iteration <- trained.model$best_iteration;
results.df$Item[i] = "";
results.df$Utility_Type[i]<-datasetName[i];
results.df$Train_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_mean;
results.df$Train_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_std;
results.df$Test_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_mean;
results.df$Test_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_std;
results.df$RMSE[i] <- rmse(error);
results.df$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
results.df$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
results.df$User_Time[i] <- time.df$user.time;
results.df$Sys_Time[i] <- time.df$sys.time;
results.df$Elapsed_Time[i] <- time.df$elapsed.time;
return(results.df);
}
#Compute results
results.df <- validatePredictions(outcomeList,results.df,validationData);
outcomeList[3]
#Train model
outcomeList <- trainModel(trainingData);
convertTimeToDataFrame <- function(time){
time.df <- data.frame(matrix(data=NA,nrow=1,ncol=3));
colnames(time.df) <- c("user.time","sys.time","elapsed.time");
time.df$user.time <- unlist(lapply(time, '[[', 1));
time.df$sys.time <- unlist(lapply(time, '[[', 2));
time.df$elapsed.time <-unlist(lapply(time, '[[', 3));
return (time.df);
}
source("C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//loadData.R");
#Data structure to keep results
results.df <- data.frame(matrix(data=NA,nrow=3,ncol=12));
colnames(results.df) <- c("Item","Utility_Type","Train_RMSE_MEAN","Train_RMSE_STD","Test_RMSE_MEAN",
"Test_RMSE_STD","RMSE","R_Squared", "MAPD","User_Time","Sys_Time","Elapsed_Time");
#Folder with training data
folder <- "C://Users//Chris//Documents//GitHub//ML_SelfHealingUtility//data//DataPoints_1K-3K-9K//";
#folder <- "//DataPoints_1K-3K-9K//";
# CONTROL CODE   ------------------------------------------------------------
modelList <- c("Linear","Discontinuous","Saturating","ALL");
modelName <- modelList[1];
datasetSize <- c("1K","3K","9K");
datasetName <- generateDataSetNames(modelName,datasetSize,0);
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
# Train function  ---------------------------------------------------------
trainModel <- function(featuresdf){
inputFeatures <- dim(featuresdf)[2] - 1; #last column is the target variable
xgb.train.data = xgb.DMatrix(data.matrix(trainingData[,1:inputFeatures]),
label = trainingData[,"UTILITY_INCREASE"],
missing = NA)
param <- list(objective = "reg:linear", base_score = 0.5)# booster="gbtree")
#Discovers the best model
time <- system.time(trained.model <-  xgb.cv(
param=param,
data = xgb.train.data,
nfold = 10,
nrounds = 2500,
early_stopping_rounds = 500,
metrics='rmse',
verbose = FALSE)
)
best_iteration <- trained.model$best_iteration;
#trained.model$evaluation_log[best_iteration]
#Get the bes model
best.model <- xgboost(param =param,  data = xgb.train.data, nrounds=best_iteration)
#convertTimeToDataFrame(time)
return(list(best.model,trained.model, convertTimeToDataFrame(time)));
}
# Validation -------------------------------------------------------------
validatePredictions <- function(modelList, results.df,validationData){
best.model <- modelList[[1]];
trained.model <- modelList[[2]];
time.df <- modelList[3]
best_iteration <- trained.model$best_iteration;
y_pred <- predict(best.model, as.matrix(validationData));
error <- y_pred - validationData$UTILITY_INCREASE;
best_iteration <- trained.model$best_iteration;
results.df$Item[i] = "";
results.df$Utility_Type[i]<-datasetName[i];
results.df$Train_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_mean;
results.df$Train_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$train_rmse_std;
results.df$Test_RMSE_MEAN[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_mean;
results.df$Test_RMSE_STD[i]<-trained.model$evaluation_log[best_iteration]$test_rmse_std;
results.df$RMSE[i] <- rmse(error);
results.df$R_Squared[i] <- r_squared(y_pred,validationData$UTILITY_INCREASE);
results.df$MAPD[i] <- mapd(y_pred,validationData$UTILITY_INCREASE);
results.df$User_Time[i] <- time.df$user.time;
results.df$Sys_Time[i] <- time.df$sys.time;
results.df$Elapsed_Time[i] <- time.df$elapsed.time;
return(results.df);
}
i <- 1;
fileName <- paste0(folder,datasetName[i],".csv");
dataf <- loadData(fileName);
#data_all <- read.csv(fileName,header = TRUE,sep=",");
featuresdf <- prepareFeatures(dataf,"Saturating");
#Extract training ad validation sets
totalData = dim(featuresdf)[1];
trainingSize = trunc(totalData * 0.7);
startTestIndex = totalData - trainingSize;
trainingData<- as.data.frame(featuresdf[1:trainingSize,]);
validationData<-as.data.frame(featuresdf[startTestIndex:totalData,]);
#Train model
outcomeList <- trainModel(trainingData);
outcomeList[3]
